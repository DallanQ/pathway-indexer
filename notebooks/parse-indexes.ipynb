{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the information of ACC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the information from [Acc Site](https://missionaries.prod.byu-pathway.psdops.com/ACC-site-index) to a CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "import csv\n",
    "\n",
    "from typing import Any, cast\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with this function we will clean our data, delete the weird characters and the empty spaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean function\n",
    "def clean(text: Any) -> str:\n",
    "    \"\"\"Convert text to a string and clean it.\"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    if isinstance(text, Tag):\n",
    "        text = text.get_text()\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \"\"\"Replace non-breaking space with normal space and remove surrounding whitespace.\"\"\"\n",
    "    text = text.replace(\" \", \" \").replace(\"\\u200b\", \"\").replace(\"\\u200a\", \" \")\n",
    "    text = re.sub(r\"(\\n\\s*)+\\n\", \"\\n\\n\", text)\n",
    "    text = re.sub(r\" +\\n\", \"\\n\", text)\n",
    "    text = re.sub(r\"\\r\\n\", \" \", text)\n",
    "    return cast(str, text.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Selectors` class contains the information of the columns that we want to extract from the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selectors:\n",
    "    def __init__(self, header, sub_header, link, text):\n",
    "        self.header = header\n",
    "        self.sub_header = sub_header\n",
    "        self.link = link\n",
    "        self.text = text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_data` function will get the data from the website and parse it to a rows list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data(soup: BeautifulSoup, selectors: Selectors) -> list:\n",
    "    \"\"\"\n",
    "    Get the data from the soup object.\n",
    "    \"\"\"\n",
    "    cur_header = None\n",
    "    cur_sub_header = None\n",
    "    rows = []  # header, subheader, title, url\n",
    "    \n",
    "    header = selectors.header\n",
    "    sub_header = selectors.sub_header\n",
    "    link = selectors.link\n",
    "    text = selectors.text\n",
    "    elems = soup.select(\"p.MsoNormal\")\n",
    "\n",
    "    for elem in elems:\n",
    "        if elem.select(sub_header):\n",
    "            sub_header_text = elem.select(sub_header)[0].text\n",
    "            cur_sub_header = clean(sub_header_text)\n",
    "        elif elem.select(header):\n",
    "            header_text = elem.select(header)[0].text\n",
    "            cur_header = clean(header_text)\n",
    "            cur_sub_header = None\n",
    "        elif elem.select(link):\n",
    "            if len(elem.select(link)) > 0 and elem.select(text):\n",
    "                link_text = elem.select(link)[0].get_attribute_list(\"href\")[0]\n",
    "                text_text = elem.select(text)[0].text\n",
    "\n",
    "            # save the row\n",
    "                rows.append(\n",
    "                    [cur_header, cur_sub_header, clean(text_text), clean(link_text)]\n",
    "                )\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_index(url, selectors: Selectors):\n",
    "    parser = \"html.parser\",\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, parser)\n",
    "    data = get_data(soup, selectors)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from ACM Site Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "acm_selectors = Selectors(\n",
    "    header = 'span[style=\"font-size:18.0pt\"]',\n",
    "    sub_header = \"b > i\",\n",
    "    link = \"a\",\n",
    "    text = \"a > span\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acm_url = \"https://missionaries.prod.byu-pathway.psdops.com/ACC-site-index\"\n",
    "acm_data = crawl_index(acm_url, acm_selectors)\n",
    "print(json.dumps(acm_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will save our data into the `acm_site.csv` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "acm_path = '../data/data_09_12_24/index/acm_site.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(acm_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Section\", \"Subsection\", \"Title\", \"URL\"])\n",
    "    writer.writerows(acm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missionary Services Site Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "missionary_selectors = Selectors(\n",
    "    header = 'b > span',\n",
    "    sub_header = 'span[style=\"font-size:16.0pt;line-height:150%\"]',\n",
    "    link = \"a\",\n",
    "    text = \"a > span\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missionary_url = \"https://missionaries.prod.byu-pathway.psdops.com/missionary-services-site-index\"\n",
    "missionary_data = crawl_index(missionary_url, missionary_selectors)\n",
    "print(json.dumps(missionary_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will save our data into the `missionary.csv` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "missionary_path = '../data/data_09_12_24/index/missionary.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(missionary_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # write headers\n",
    "    writer.writerow([\"Section\", \"Subsection\", \"Title\", \"URL\"])\n",
    "    writer.writerows(missionary_data[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the url for acm and missionary indexes in one list\n",
    "indexes = acm_data + missionary_data[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_path = '../data/data_09_12_24/index/indexes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(indexes_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # write headers\n",
    "    writer.writerow([\"Section\", \"Subsection\", \"Title\", \"URL\"])\n",
    "    writer.writerows(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "acm_df = pd.read_csv(acm_path)\n",
    "missionary_df = pd.read_csv(missionary_path)\n",
    "indexes_df = pd.read_csv(indexes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(acm_df), len(missionary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(acm_df) + len(missionary_df), len(indexes_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
