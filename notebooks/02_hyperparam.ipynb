{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a43a4b1-b424-41d1-8d39-153cc37f3a08",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization\n",
    "\n",
    "This week will use [Optuna](https://optuna.org/), a library to make finding the best hyperparameters easy.\n",
    "\n",
    "We will use it to discover the best approach for chunking documents and indexing the chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:51:20.014116631Z",
     "start_time": "2024-06-02T06:51:20.013126125Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f82c275efc6aa93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:51:27.966680878Z",
     "start_time": "2024-06-02T06:51:20.554743009Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "\n",
    "from llama_index.core import Document, VectorStoreIndex, set_global_handler\n",
    "import optuna\n",
    "import pandas as pd\n",
    "\n",
    "# Modifications\n",
    "from utils.retrieve import objective, generate_quote_ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8255e29444203f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:51:28.392069312Z",
     "start_time": "2024-06-02T06:51:27.969236719Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# configure\n",
    "filename = \"everdell.md\"\n",
    "qa_filename = \"everdell-selected.csv\"\n",
    "ngram_size = 2  # use 2 instead of 3 so we don't skip 2-word header chunks\n",
    "f_beta = 3  # weight recall 3 times as important as precision in f-score\n",
    "n_trials = 25  # number of Optuna trials\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da5396-c1fb-493c-a47d-61739303a222",
   "metadata": {},
   "source": [
    "## Read question-answers and generate ngrams from manual quotes\n",
    "\n",
    "The question-answers file has been augmented by a human to include the sentences/paragraphs from the manual that are needed (necessary and sufficient) to answer each question.\n",
    "\n",
    "To evaluate the quality of a list of chunks retrieved from an index, we want to compare the sentences/paragraphs in the chunks against the sentences/paragraphs specified by the human in the question-answer file.\n",
    "\n",
    "To do the comparison we can't simply check for equality, because the retrieved chunk may only overlap part of the human-specified sentence/paragraph. So we generate _ngrams_ for the retrieved chunks and the human-specified sentence/paragraphs, and compare how many ngrams they have in common using the standard precision and recall metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507f257-7671-4fdc-a069-187289b61f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read question-answers\n",
    "qa_df = pd.read_csv(f\"data/{qa_filename}\", na_filter=False)\n",
    "print(len(qa_df))\n",
    "qa_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4e00f0-db84-46c5-8878-b3247a197b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we shouldn't include questions in the *test* set right now,\n",
    "# but people are still adding the manual quotes,\n",
    "# and since we have so few questions with manual quotes so far\n",
    "# we will use all of them for this demo.\n",
    "\n",
    "# keep only rows with at least 1 manual quote\n",
    "qa_df = qa_df[qa_df[\"manual quote 1\"].notna() & (qa_df[\"manual quote 1\"] != \"\")]\n",
    "print(len(qa_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014b748-be9d-4464-abb1-a1a95bedf0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate bigrams (ngram size=2) for each manual quote\n",
    "# and store them in the question_ngrams dictionary\n",
    "question_ngrams = generate_quote_ngrams(qa_df, ngram_size)\n",
    "print(len(question_ngrams))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a50357-185e-44ce-8a46-de103f83b9f4",
   "metadata": {},
   "source": [
    "## Read the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9d9ac-b0ac-4ed9-9430-e864e0f5df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load document\n",
    "documents = []\n",
    "with open(f\"data/{filename}\", \"r\", encoding=\"utf-8\") as file:\n",
    "    document = Document(\n",
    "        text=file.read(),\n",
    "        metadata={\"filename\": filename},\n",
    "    )\n",
    "    # add the document to a single-entry documents list that we will use below\n",
    "    documents.append(document)\n",
    "print(len(documents[0].text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15844d-4cc3-4fbd-9c97-2352caed3a25",
   "metadata": {},
   "source": [
    "## Optimize hyperparameters by creating an index and evaluating the retrieved chunks\n",
    "\n",
    "Creating an index involves a sequence of steps (a pipeline). Each step is configured using hyperparameters:\n",
    "\n",
    "- split each document into chunks\n",
    "- add metadata - e.g., document title, summary of previous and next chunks, pointer to parent chunk\n",
    "- add an embedding (vector) - decide whether you want the embedding to include chunk metadata or just the text\n",
    "- index the chunk - choose a vector store and index the embeddings, keywords, or both\n",
    "\n",
    "Evaluate the retrieved chunks\n",
    "\n",
    "- issue the queries\n",
    "- compare the ngrams in the retrieved chunks to the ngrams in the human-specified sentences/paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2aacf-8368-4796-9998-b209c24a3569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask Optuna to find the best hyperparameters\n",
    "\n",
    "study_name = \"test\"  # Unique identifier of the study.\n",
    "storage_name = f\"sqlite:///optuna-{study_name}.db\"\n",
    "print(\n",
    "    f\"To see a dashboard, open a terminal, activate the virtual environment, and run: optuna-dashboard {storage_name}\"\n",
    ")\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    ")\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f8ef63-8ded-440d-875e-3e6216ab503b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
