{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/isaiaszc/pathway/pathway-\n",
      "[nltk_data]     indexer/.venv/lib/python3.12/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from llama_index.core import Document\n",
    "\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.vector_stores.types import VectorStoreQueryMode\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "import chromadb\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "from utils.hyper_functions import extract_index_metadata, AltNodeParser, run_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.getenv(\"DATA_PATH\")\n",
    "\n",
    "origin_paths = [f\"../.{datapath}out/from_html/\", f\"../.{datapath}out/from_pdf/\"]\n",
    "embed_model_name = \"text-embedding-3-large\"\n",
    "\n",
    "split_by = \"paragraph\"  ### trial.suggest_categorical(\"split_by\", [\"sentence\", \"paragraph\", \"both\"])\n",
    "embed_prev_next_sentences = 0  ### trial.suggest_int(\"embed_prev_next_sentences\", 0, 5)\n",
    "embed_prev_next_paragraphs = (\n",
    "    1  ### trial.suggest_int(\"embed_prev_next_paragraphs\", 1, 4)\n",
    ")\n",
    "max_embed_length = 400\n",
    "# Two problems with embedding index headers:\n",
    "# 1. The index titles are often the exact same as our test questions, leading to data leakage\n",
    "#    which makes our numbers too good.\n",
    "# 2. The index titles may refer to specific parts of the page, but we associate them with the entire page\n",
    "#    which means that every chunk on the page appears equally relevant and gets our retriever confused.\n",
    "# So I think we'll have to rely on embedding markdown headers\n",
    "embed_index_headers = False\n",
    "embed_md_headers = True  ### trial.suggest_categorical(\"embed_md_headers\", [True])\n",
    "include_prev_next_paragraphs = 2\n",
    "max_include_length = 700\n",
    "include_index_headers = (\n",
    "    False  ### trial.suggest_categorical(\"include_index_headers\", [False])\n",
    ")\n",
    "include_md_headers = True  ### trial.suggest_categorical(\"include_md_headers\", [True])\n",
    "splitter_name = \"alt_splitter\"\n",
    "\n",
    "# define index\n",
    "query_mode = VectorStoreQueryMode.DEFAULT\n",
    "index_type = \"chromadb\"\n",
    "\n",
    "retriever_threshold = 0.0\n",
    "retriever_k = 35\n",
    "sparse_k = retriever_k * 5\n",
    "rerank_model = \"rerank-lite-1\"\n",
    "rerank_threshold = 0.21\n",
    "rerank_k = 17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files list length:  564\n",
      "Metadata added to documents\n"
     ]
    }
   ],
   "source": [
    "# Read the document names from the directories:\n",
    "files_list = [path + item for path in origin_paths for item in os.listdir(path)]\n",
    "\n",
    "files_list.sort()\n",
    "\n",
    "print(\"Files list length: \", len(files_list))\n",
    "\n",
    "documents = []\n",
    "\n",
    "for i, filepath in enumerate(files_list):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        document = Document(text=file.read(), metadata={\"filepath\": filepath})\n",
    "\n",
    "        # add the document to a single entry list\n",
    "        documents.append(document)\n",
    "\n",
    "\n",
    "documents = [extract_index_metadata(doc) for doc in documents]\n",
    "\n",
    "metadata_keys = set()\n",
    "for doc in documents:\n",
    "    for key in doc.metadata:\n",
    "        metadata_keys.add(key)\n",
    "\n",
    "documents = documents[:10]\n",
    "\n",
    "print(\"Metadata added to documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = OpenAIEmbedding(\n",
    "    model=embed_model_name,\n",
    "    embed_batch_size=100,\n",
    "    max_retries=25,\n",
    "    timeout=180,\n",
    "    reuse_client=True,\n",
    ")\n",
    "\n",
    "splitter = AltNodeParser().from_defaults(\n",
    "    split_by=split_by,\n",
    "    embed_prev_next_sentences=embed_prev_next_sentences,\n",
    "    embed_prev_next_paragraphs=embed_prev_next_paragraphs,\n",
    "    max_embed_length=max_embed_length,\n",
    "    embed_index_headers=embed_index_headers,\n",
    "    embed_md_headers=embed_md_headers,\n",
    "    include_prev_next_paragraphs=include_prev_next_paragraphs,\n",
    "    max_include_length=max_include_length,\n",
    "    include_index_headers=include_index_headers,\n",
    "    include_md_headers=include_md_headers,\n",
    ")\n",
    "\n",
    "# define index\n",
    "query_mode = VectorStoreQueryMode.DEFAULT\n",
    "index_type = \"chromadb\"\n",
    "\n",
    "chroma_client = chromadb.EphemeralClient()\n",
    "# delete collection if it exists\n",
    "if any(coll.name == \"test\" for coll in chroma_client.list_collections()):\n",
    "    chroma_client.delete_collection(\"test\")\n",
    "chroma_collection = chroma_client.create_collection(\"test\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline\n",
      "len of all_nodes 10\n",
      "len of nodes_with_progress 10\n",
      "Nodes inserted: 59\n",
      "Pipeline finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting pipeline\")\n",
    "index, nodes = run_pipeline(documents, splitter, embed_model, vector_store, False)\n",
    "\n",
    "print(\"Pipeline finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'header_1': '6.4 Pathway Certificates',\n",
       " 'heading': '6. Student Records',\n",
       " 'subheading': \"''\",\n",
       " 'title': '6.4 Pathway Certificates',\n",
       " 'title_tag': '6.4 Pathway Certificates',\n",
       " 'url': 'https://www.byupathway.edu/policies/handbook/6-4-pathway-certificates-ed',\n",
       " 'sequence': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[1].metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.4 Pathway Certificates\\n\\nStudents who have completed PathwayConnect and are eligible to receive a certificate can print their own certificates. To do so, students should:\\n\\n1. Log in to their BYU-Pathway Portal\\n2. Click on their name in the top, right corner\\n3. Click PathwayConnect Certificates\\n4. The certificate will appear with the name and completion year as a printable PDF'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[1].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a retriever from the index\n",
    "retriever = index.as_retriever(\n",
    "    vector_store_query_mode=query_mode,\n",
    "    similarity_top_k=retriever_k,\n",
    "    sparse_top_k=sparse_k,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
