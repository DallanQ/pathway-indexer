{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# with unstructured\n",
    "\n",
    "from unstructured_client import UnstructuredClient\n",
    "from unstructured_client.models import shared\n",
    "from unstructured_client.models.errors import SDKError\n",
    "import os\n",
    "import time\n",
    "\n",
    "from utils.markdown_utils import unstructured_elements_to_markdown\n",
    "\n",
    "import logging\n",
    "\n",
    "# Set the logging level to WARNING or higher to suppress INFO messages\n",
    "logging.basicConfig(level=logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 295\n"
     ]
    }
   ],
   "source": [
    "out_path = \"../data/out_sep_4/from_pdf/\"\n",
    "origin_path = \"../data/crawl/pdf/\"\n",
    "\n",
    "# Get all the filenames from the origin path\n",
    "file_names = os.listdir(origin_path)\n",
    "file_names.sort()\n",
    "file_names = [{\"path\": name} for name in file_names]\n",
    "\n",
    "print(\"len:\", len(file_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting PDF data to TXT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = UnstructuredClient(\n",
    "    api_key_auth=os.environ[\"UNSTRUCTURED_API_KEY\"],\n",
    "    server_url=os.environ[\"UNSTRUCTURED_SERVER_URL\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf_to_txt(file):\n",
    "    file_path = origin_path + file[\"path\"]\n",
    "    print(\"Processing file:\", file_path)\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        # Note that this currently only supports a single file\n",
    "        files = shared.Files(\n",
    "            content=f.read(),\n",
    "            file_name=file_path,\n",
    "        )\n",
    "\n",
    "    req = shared.PartitionParameters(\n",
    "        files=files,\n",
    "        # Other partition params\n",
    "        strategy=\"fast\",\n",
    "        languages=[\"eng\"],\n",
    "        encoding=\"utf-8\",\n",
    "        # split_pdf_allow_failed=True\n",
    "        # pdf_infer_table_structure=True,\n",
    "        # skip_infer_table_types=[],\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        resp = s.general.partition(req)\n",
    "        # print(len(resp.elements))\n",
    "    except SDKError as e:\n",
    "        print(e)\n",
    "        return True\n",
    "    except Exception as e:  # if the SDKError is not caught\n",
    "        print(\"Another exception\", e)\n",
    "        return True\n",
    "    simple_md = unstructured_elements_to_markdown(resp.elements)\n",
    "\n",
    "    # get the size of the file\n",
    "    file[\"size\"] = len(simple_md)\n",
    "    # file_names[idx] = {\"path\": file[\"path\"], \"size\": len(simple_md)}\n",
    "\n",
    "    file_out = out_path + file[\"path\"].replace(\".pdf\", \".txt\")\n",
    "    # file_out = file_out.replace(\"pdf\", \"txt\")\n",
    "\n",
    "    with open(file_out, \"w\") as f:\n",
    "        f.write(simple_md)\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ../data/crawl/pdf/Policy-Executive-Secretaries--Communication.pdf\n"
     ]
    }
   ],
   "source": [
    "for file in file_names:\n",
    "    with_error = parse_pdf_to_txt(file)\n",
    "    try_limit = 3\n",
    "    while with_error and try_limit > 0:\n",
    "        with_error = parse_pdf_to_txt(file)\n",
    "        try_limit -= 1\n",
    "        time.sleep(4)\n",
    "\n",
    "    if try_limit == 0:\n",
    "        print(\"Error processing file:\", file[\"path\"])\n",
    "        file[\"unstructured_error\"] = True\n",
    "\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the files with errors\n",
    "file_names_with_errors = [file for file in file_names if \"unstructured_error\" in file]\n",
    "print(file_names_with_errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual verification the files with smallest size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT: The next piece of code is unnecessary, was writed just because the original file_names variable was empty after running the last function (probably a bug in the function or by ram memory).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the files names from the out path\n",
    "# file_names_out = os.listdir(out_path)\n",
    "# file_names_out.sort()\n",
    "\n",
    "# file_names_out = [{\"path\": name} for name in file_names_out]\n",
    "\n",
    "# get the size of each file\n",
    "# for idx, file in enumerate(file_names):\n",
    "#     file_path = out_path + file[\"path\"].replace(\".pdf\", \".txt\")\n",
    "#     with open(file_path, \"r\") as f:\n",
    "#         file[\"size\"] = len(f.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the TXT info to Markdown with Llama-Parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
    "    parsing_instruction=(\n",
    "        \"Convert the provided text into accurate and well-structured Markdown format, closely resembling the original PDF structure. \"\n",
    "        \"Use headers from H1 to H3, with H1 for main titles, H2 for sections, and H3 for subsections. \"\n",
    "        \"Detect any bold, large, or all-uppercase text as headers. \"\n",
    "        \"Preserve bullet points and numbered lists with proper indentation to reflect nested lists. \"\n",
    "        \"if it is not a header, ensure that bold and italic text is properly formatted using double **asterisks** for bold and single *asterisks* for italic\"\n",
    "        \"Detect and correctly format blockquotes using the '>' symbol for any quoted text. \"\n",
    "        \"When processing text, pay attention to line breaks that may incorrectly join or split words. \"\n",
    "        \"Automatically correct common errors, such as wrongly concatenated words or broken lines, to ensure the text reads naturally\"\n",
    "        \"If code snippets or technical commands are found, enclose them in triple backticks ``` for proper formatting. \"\n",
    "        \"If any tables are detected, parse them as a title (bold header) followed by list items\"\n",
    "        \"If you see the same header multiple times, merge them into one.\"\n",
    "        \"If images contain important text, transcribe only the highlighted or boxed text and ignore general background text. \"\n",
    "        \"Do not enclose fragments of code/Markdown or any other content in triple backticks unless they are explicitly formatted as code blocks in the original text. \"\n",
    "        \"The final output should be a clean, concise Markdown document closely reflecting the original PDF's intent and structure without adding any extra text.\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extractor = {\".txt\": parser}\n",
    "\n",
    "\n",
    "def parse_txt_to_md(file):\n",
    "    load_file = out_path + file.replace(\".pdf\", \".txt\")\n",
    "\n",
    "    if os.path.exists(load_file.replace(\".txt\", \".md\")):\n",
    "        print(f\"Markdown file {load_file.replace(\".txt\",\".md\")} already exists. Skipping.\")\n",
    "        return 0\n",
    "\n",
    "    documents = SimpleDirectoryReader(\n",
    "        input_files=[load_file], file_extractor=file_extractor\n",
    "    ).load_data()\n",
    "\n",
    "    size = sum([len(doc.text) for doc in documents])\n",
    "\n",
    "    if size == 0:\n",
    "        print(f\"Error parsing {load_file}. Review the limit credits.\")\n",
    "        return 0\n",
    "\n",
    "    out_name = f\"{out_path}{file.replace('.pdf', '.md')}\"\n",
    "    # out_name = file.replace(\".txt\", \".md\")\n",
    "    with open(out_name, \"w\") as f:\n",
    "        for doc in documents:\n",
    "            f.write(doc.text)\n",
    "            f.write(\"\\n\\n\")\n",
    "        print(out_name, \"saved.\")\n",
    "\n",
    "    return size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 93479503-a547-4ac2-bf84-39a698c2479b\n",
      "Error while parsing the file '<bytes/buffer>': 'markdown'\n",
      "Error parsing ../data/out_sep_4/from_pdf/Policy-Executive-Secretaries--Communication.txt. Review the limit credits.\n",
      "size parsed: 0, file size: 1219, diff: 1219\n"
     ]
    }
   ],
   "source": [
    "for file in file_names:\n",
    "    limit_try = 2\n",
    "    size = parse_txt_to_md(file[\"path\"])\n",
    "\n",
    "    print(\n",
    "        f\"size parsed: {size}, file size: {file['size']}, diff: {file['size'] - size}\"\n",
    "    )\n",
    "    while size < (file[\"size\"] - 300) and limit_try > 0 and size != 0:\n",
    "        try:\n",
    "            limit_try -= 1\n",
    "            time.sleep(2)\n",
    "            size = parse_txt_to_md(file[\"path\"])\n",
    "        except Exception as e:\n",
    "            limit_try -= 1\n",
    "            print(f\"Error processing file {file['path']} - {limit_try} tries left.\")\n",
    "            time.sleep(2)\n",
    "\n",
    "    if limit_try == 0 and size != 0:\n",
    "        print(f\"Error processing file {file['path']} - {limit_try} tries left.\")\n",
    "        file[\"llama_error\"] = True\n",
    "\n",
    "    if size != 0:\n",
    "        # delete the txt file\n",
    "        loaded_file = out_path + file[\"path\"].replace(\".pdf\", \".txt\")\n",
    "        if os.path.exists(loaded_file):\n",
    "            os.remove(loaded_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the files that could not be loadedand has an error attribute\n",
    "for file in file_names:\n",
    "    if \"llama_error\" in file:\n",
    "        print(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review if there are files with error to review them manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_with_error = [file for file in file_names if \"error\" in file]\n",
    "\n",
    "print(files_with_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros\n",
    "\n",
    "- Cheapest because it makes less requests to the API\n",
    "- Most accurate because it uses the text directly\n",
    "- Well structured result\n",
    "\n",
    "### Cons\n",
    "\n",
    "- We are ignoring completely the image and only using the text related. This could be a problem if the image contains important information\n",
    "- Sometimes the order of the text is not the same as the PDF because the structure (i.e. 18)\n",
    "\n",
    "### warnings\n",
    "\n",
    "- In some PDF's thera are text inside the images (to complete the example, this could be a problem, for example, a specific price)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
