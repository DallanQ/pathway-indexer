{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "    \n",
    "def clean_markdown(text):\n",
    "    text = re.sub(r'```markdown+', '', text)\n",
    "    \n",
    "    # Remove Markdown backticks\n",
    "    text = re.sub(r'```+', '', text)\n",
    "\n",
    "    # Remove inline code backticks (`text`)\n",
    "    text = re.sub(r'`+', '', text)\n",
    "\n",
    "    text = re.sub(r'\\[Print\\]\\(javascript:window\\.print\\(\\)\\)', '', text)\n",
    "    \n",
    "    # Remove list of links with same anchors\n",
    "    text = re.sub(r'(?:(https?:\\/\\/[^\\s]+)\\s+){2,}', '', text)  # Remove repeated links\n",
    "\n",
    "    # Replace [link](#) and [link](url) with link text only\n",
    "    text = re.sub(r'\\[([^\\]]+)\\]\\(([^)]+)\\)', r'\\1', text)\n",
    "\n",
    "    # Remove lists of links to the same page (e.g., [All](#) [Web Pages](#))\n",
    "    text = re.sub(r'(\\[([^\\]]+)\\]\\(#\\))+(?:\\s|,)*', '', text)\n",
    "    \n",
    "    # Regular expression to remove unnecessary text from \n",
    "    # knowledge base articles\n",
    "    # Remove specific table headers\n",
    "    text = re.sub(r'\\| \\*\\*Bot Information\\*\\* \\|\\n\\| --- \\|', '', text)\n",
    "    text = re.sub(r'\\| \\*\\*Information\\*\\* \\|\\n\\| --- \\|', '', text)\n",
    "    text = re.sub(r'Views:\\n\\n\\|\\s*Article Overview\\s*\\|\\s*\\n\\|\\s*---\\s*\\|\\s*\\n\\|.*?\\|','',text,flags=re.DOTALL)\n",
    "    text = re.sub(r'\\|\\s*Information\\s*\\|\\s*\\n\\|\\s*---\\s*\\|\\s*\\n\\|.*?\\|', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'\\|\\s*Bot Information\\s*\\|\\s*\\n\\|\\s*---\\s*\\|\\s*\\n\\|.*?\\|', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'\\n\\s*\\*\\*Information\\*\\*\\s*\\n', '\\n', text)\n",
    "    text = re.sub(r'##? Views:\\n\\n\\| \\*\\*Article Overview\\*\\* \\|\\n\\| --- \\|\\n\\|.*?\\|', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'Views:\\n\\n\\| \\*\\*Article Overview\\*\\* \\|\\n\\| --- \\|\\n\\|.*?\\|', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'^\\| Information \\|\\n', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\*\\s*(Home|Knowledge Base - Home|KA-\\d+)\\s*\\n', '', text)\n",
    "    text = re.sub(r\"(You’re offline.*?Knowledge Articles|Contoso, Ltd\\.|BYU-Pathway Worldwide|Toggle navigation[.\\w\\s\\*\\+\\-\\:]+|Search Filter|Search\\n|Knowledge Article Key:)\", '', text)\n",
    "    text = re.sub(r\"You’re offline\\. This is a read only version of the page\\.\", '', text)\n",
    "    \n",
    "    # Others regular expressions to remove unnecessary text\n",
    "    # Remove empty headers\n",
    "    text = re.sub(r'^#+\\s*$', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove text from WhatsApp navigation\n",
    "    text = re.sub(r\"Copy link\\S*\", 'Copy link', text)\n",
    "    \n",
    "    # Remove text from the hall foundation menu\n",
    "    # text = re.sub(r\"(Skip to content|Menu|[*+-].*)\\n\", '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove broken links\n",
    "    text = re.sub(r'\\[([^\\]]+)\\]\\.\\n\\n\\((http[^\\)]+)\\) \\(([^)]+)\\)\\.', r'\\1 (\\3).',  text)\n",
    "    \n",
    "    # Remove consecutive blank lines\n",
    "    text = re.sub(r'\\n\\s*\\n\\s*\\n', '\\n\\n', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def clean_md(input_path, output_path):\n",
    "    # Create the new directory if it doesn't exist\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    for file in os.listdir(input_path):\n",
    "        if file.endswith('.md'):\n",
    "            print(f'Cleaning file: {file}')\n",
    "            input_file_path = os.path.join(input_path, file)\n",
    "            \n",
    "            # Read the original markdown file\n",
    "            with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                \n",
    "            # Clean the markdown content\n",
    "            cleaned_content = clean_markdown(content)\n",
    "            \n",
    "            # Define the new file path in the output folder\n",
    "            output_file_path = os.path.join(output_path, file)\n",
    "            \n",
    "            # Write the cleaned content to the new file\n",
    "            with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(cleaned_content)\n",
    "            print(f'Cleaned file saved as: {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory_path = '../data/data_16_09_24/out/from_html/'\n",
    "output_directory_path = '../data/data_16_09_24/clean_md/out/' \n",
    "clean_md(input_directory_path, output_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
