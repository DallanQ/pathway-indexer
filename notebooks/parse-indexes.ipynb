{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the information of ACC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the information from [Acc Site](https://missionaries.prod.byu-pathway.psdops.com/ACC-site-index) to a CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "import csv\n",
    "\n",
    "from typing import Any, cast\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with this function we will clean our data, delete the weird characters and the empty spaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean function\n",
    "def clean(text: Any) -> str:\n",
    "    \"\"\"Convert text to a string and clean it.\"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    if isinstance(text, Tag):\n",
    "        text = text.get_text()\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \"\"\"Replace non-breaking space with normal space and remove surrounding whitespace.\"\"\"\n",
    "    text = text.replace(\" \", \" \").replace(\"\\u200b\", \"\").replace(\"\\u200a\", \" \")\n",
    "    text = re.sub(r\"(\\n\\s*)+\\n\", \"\\n\\n\", text)\n",
    "    text = re.sub(r\" +\\n\", \"\\n\", text)\n",
    "    text = re.sub(r\"\\r\\n\", \" \", text)\n",
    "    return cast(str, text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selectors:\n",
    "    def __init__(self, header, sub_header, link, text):\n",
    "        self.header = header\n",
    "        self.sub_header = sub_header\n",
    "        self.link = link\n",
    "        self.text = text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_data` function will get the data from the website and parse it to a rows list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data(soup: BeautifulSoup, selectors: Selectors) -> list:\n",
    "    \"\"\"\n",
    "    Get the data from the soup object.\n",
    "    \"\"\"\n",
    "    cur_header = None\n",
    "    cur_sub_header = None\n",
    "    rows = []  # header, subheader, title, url\n",
    "    \n",
    "    header = selectors.header\n",
    "    sub_header = selectors.sub_header\n",
    "    link = selectors.link\n",
    "    text = selectors.text\n",
    "    elems = soup.select(\"p.MsoNormal\")\n",
    "\n",
    "    for elem in elems:\n",
    "        if elem.select(sub_header):\n",
    "            sub_header_text = elem.select(sub_header)[0].text\n",
    "            cur_sub_header = clean(sub_header_text)\n",
    "        elif elem.select(header):\n",
    "            header_text = elem.select(header)[0].text\n",
    "            cur_header = clean(header_text)\n",
    "            cur_sub_header = None\n",
    "        elif elem.select(link):\n",
    "            if len(elem.select(link)) > 0 and elem.select(text):\n",
    "                link_text = elem.select(link)[0].get_attribute_list(\"href\")[0]\n",
    "                text_text = elem.select(text)[0].text\n",
    "\n",
    "            # save the row\n",
    "                rows.append(\n",
    "                    [cur_header, cur_sub_header, clean(text_text), clean(link_text)]\n",
    "                )\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from ACC Site Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors = Selectors(\n",
    "    header = 'span[style=\"font-size:18.0pt\"]',\n",
    "    sub_header = \"b > i\",\n",
    "    link = \"a\",\n",
    "    text = \"a > span\",\n",
    ")\n",
    "\n",
    "def crawl_acm_index(selectors: Selectors):\n",
    "    parser = \"html.parser\",\n",
    "    url = \"https://missionaries.prod.byu-pathway.psdops.com/ACC-site-index\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, parser)\n",
    "    data = get_data(soup, selectors)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = crawl_acm_index(selectors)\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will save our data into the `acm_site.csv` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../CSVs/acm_site.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missionary Services Site Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors = Selectors(\n",
    "    header = 'b > span',\n",
    "    sub_header = 'span[style=\"font-size:16.0pt;line-height:150%\"]',\n",
    "    link = \"a\",\n",
    "    text = \"a > span\",\n",
    ")\n",
    "\n",
    "def crawl_missionary_index(selectors: Selectors):\n",
    "    parser = \"html.parser\",\n",
    "    url = \"https://missionaries.prod.byu-pathway.psdops.com/missionary-services-site-index\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, parser)\n",
    "    data = get_data(soup, selectors)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = crawl_missionary_index(selectors)\n",
    "print(json.dumps(data2, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will save our data into the `missionary.csv` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../CSVs/missionary.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(data2[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
